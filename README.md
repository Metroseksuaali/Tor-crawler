# Tor Crawler

ğŸ” Turvallinen ja eettinen web crawler .onion-sivustojen tutkimiseen Tor-verkossa.

**Tarkoitus:** Tutkimus- ja oppimistarkoitukset
**Tekniikka:** Python 3.9+ | aiohttp | BeautifulSoup | Tor SOCKS5

---

## ğŸ“‹ SisÃ¤llysluettelo

- [Ominaisuudet](#-ominaisuudet)
- [Teknologiavalinnat](#-teknologiavalinnat)
- [Esivaatimukset](#-esivaatimukset)
- [Asennus](#-asennus)
- [KÃ¤yttÃ¶](#-kÃ¤yttÃ¶)
- [Konfiguraatio](#-konfiguraatio)
- [Datan kÃ¤sittely](#-datan-kÃ¤sittely)
- [Arkkitehtuuri](#-arkkitehtuuri)
- [Turvallisuus ja etiikka](#-turvallisuus-ja-etiikka)
- [VianmÃ¤Ã¤ritys](#-vianmÃ¤Ã¤ritys)

---

## âœ¨ Ominaisuudet

- âœ… **Tor-integraatio:** Kaikki liikenne kulkee Tor-verkon kautta (SOCKS5-proxy)
- âœ… **Asynkroninen:** Tehokas rinnakkaiskÃ¤sittely asyncio:lla
- âœ… **Rate limiting:** Konfiguroitava viive pyyntÃ¶jen vÃ¤lillÃ¤ (eettinen crawlaus)
- âœ… **BFS-algoritmi:** Leveyssuuntainen lÃ¤pikÃ¤ynti syvyydenrajoituksella
- âœ… **Kaksi tallennusvaihtoehtoa:** JSON (NDJSON) ja SQLite
- âœ… **HTML-parsinta:** BeautifulSoup + linkkien suodatus
- âœ… **VirheenkÃ¤sittely:** Timeout, connection errors, retry-logiikka
- âœ… **Domain-rajaus:** Vain .onion-sivustot, konfiguroitavat domain-rajoitukset
- âœ… **CLI-kÃ¤yttÃ¶liittymÃ¤:** Helppo kÃ¤yttÃ¶ komentoriviltÃ¤
- âœ… **Jatkettava crawlaus:** Voit pysÃ¤yttÃ¤Ã¤ ja jatkaa myÃ¶hemmin

---

## ğŸ¯ Teknologiavalinnat

### Miksi Python + aiohttp?

**Vertaillut vaihtoehdot:**
1. **Python + aiohttp** â­ (valittu)
2. Node.js + axios
3. Rust + reqwest

**Valintaperusteet:**
- âœ… KypsÃ¤ Tor-ekosysteemi (stem-kirjasto)
- âœ… Erinomainen scraping-tuki (BeautifulSoup)
- âœ… Asynkroninen suoritus (asyncio)
- âœ… Helppo oppia ja yllÃ¤pitÃ¤Ã¤
- âœ… Data science -integraatio (pandas, numpy)

---

## ğŸ”§ Esivaatimukset

### 1. Python 3.9+

Tarkista versio:
```bash
python3 --version
```

### 2. Tor

Crawleri tarvitsee kÃ¤ynnissÃ¤ olevan Tor-instanssin.

**Linux/macOS:**
```bash
# Debian/Ubuntu
sudo apt install tor
sudo systemctl start tor

# macOS (Homebrew)
brew install tor
brew services start tor
```

**Windows:**
- Lataa [Tor Expert Bundle](https://www.torproject.org/download/tor/)
- TAI kÃ¤ynnistÃ¤ Tor Browser (sisÃ¤ltÃ¤Ã¤ SOCKS-proxyn)

**Docker:**
```bash
docker run -d -p 9050:9050 --name tor dperson/torproxy
```

**Testaa ettÃ¤ Tor toimii:**
```bash
curl --socks5-hostname 127.0.0.1:9050 https://check.torproject.org/api/ip
```

PitÃ¤isi palauttaa: `{"IsTor": true, ...}`

---

## ğŸ“¦ Asennus

### 1. Kloonaa repository
```bash
git clone <repository-url>
cd Tor-crawler
```

### 2. Luo virtuaaliympÃ¤ristÃ¶ (suositeltu)
```bash
python3 -m venv venv
source venv/bin/activate  # Linux/macOS
# TAI
venv\Scripts\activate  # Windows
```

### 3. Asenna riippuvuudet
```bash
pip install -r requirements.txt
```

### 4. Konfiguroi crawler

Kopioi esimerkkikonfiguraatio:
```bash
cp config.example.yaml config.yaml
```

Muokkaa `config.yaml`:
```yaml
crawler:
  start_url: "http://your-target.onion"  # âš ï¸ LisÃ¤Ã¤ tÃ¤hÃ¤n tutkittava .onion-osoite
  max_depth: 2
  max_pages: 50
  request_delay: 3.0  # TÃ„RKEÃ„: Ã„lÃ¤ poista!
```

---

## ğŸš€ KÃ¤yttÃ¶

### Peruskomento

```bash
python main.py --config config.yaml
```

### Komentoriviparametrit

```bash
# KÃ¤ytÃ¤ kaikki asetukset komentoriviltÃ¤
python main.py --start-url "http://example.onion" --max-pages 50 --max-depth 2

# SQLite-tallennus
python main.py --config config.yaml --storage sqlite

# Muuta rate limiting
python main.py --config config.yaml --delay 5.0

# Debug-tila
python main.py --config config.yaml --log-level DEBUG
```

### Esimerkkiajo

```bash
# Aloita pienellÃ¤ testillÃ¤
python main.py \
  --start-url "http://example.onion" \
  --max-pages 10 \
  --max-depth 1 \
  --delay 3.0 \
  --storage json
```

### Keskeytys ja jatkaminen

Voit keskeyttÃ¤Ã¤ crawlauksen (`Ctrl+C`) ja jatkaa myÃ¶hemmin:
```bash
# Crawler lataa automaattisesti aiemmin kÃ¤ydyt URL:t
python main.py --config config.yaml
```

---

## âš™ï¸ Konfiguraatio

### YAML-tiedosto (config.yaml)

```yaml
# Tor-asetukset
tor:
  proxy_host: "127.0.0.1"
  proxy_port: 9050
  control_port: 9051
  use_stem: false  # true = mahdollistaa IP-vaihdon

# Crawler-asetukset
crawler:
  start_url: "http://example.onion"
  max_depth: 3              # Kuinka monta linkkitasoa
  max_pages: 100            # Maksimi sivuja yhteensÃ¤
  max_pages_per_domain: 50  # Maksimi per domain
  request_delay: 2.0        # Sekuntia pyyntÃ¶jen vÃ¤lillÃ¤
  request_timeout: 30       # Timeout sekunteina
  follow_external_onion: true  # Seuraa muita .onion-domaineja
  allowed_domains: []       # TyhjÃ¤ = kaikki, tai lista: ["a.onion", "b.onion"]

# Tallennus
storage:
  storage_type: "json"      # "json" tai "sqlite"
  output_dir: "./data"
  json_filename: "crawled_pages.json"
  sqlite_filename: "crawler.db"

# Lokitus
log_level: "INFO"
```

### YmpÃ¤ristÃ¶muuttujat

Luo `.env`-tiedosto (kopioi `.env.example`):
```env
TOR_PROXY_HOST=127.0.0.1
TOR_PROXY_PORT=9050
START_URL=http://example.onion
MAX_DEPTH=3
MAX_PAGES=100
LOG_LEVEL=INFO
```

**Prioriteetti:** Komentorivi > YmpÃ¤ristÃ¶muuttujat > YAML

---

## ğŸ“Š Datan kÃ¤sittely

### JSON-tallennus (NDJSON)

Jokainen rivi = yksi JSON-objekti:

```json
{"url": "http://example.onion/page1", "status": 200, "title": "Esimerkki", "depth": 1, "timestamp": "2025-01-01T12:00:00", "links": ["http://example.onion/page2"], "text_preview": "...", "meta": {}, "error": null}
{"url": "http://example.onion/page2", "status": 200, "title": "Toinen", "depth": 2, ...}
```

**Lukeminen Pythonilla:**
```python
import json

with open('data/crawled_pages.json', 'r') as f:
    for line in f:
        page = json.loads(line)
        print(page['url'], page['title'])
```

**Lukeminen pandas:lla:**
```python
import pandas as pd

df = pd.read_json('data/crawled_pages.json', lines=True)
print(df[['url', 'status', 'title']])
```

### SQLite-tallennus

**Rakenne:**
- `pages`: url, status, title, depth, timestamp, text_preview, error, meta
- `links`: source_url, target_url

**Kyselyt:**
```sql
-- Kaikki onnistuneet sivut
SELECT url, title FROM pages WHERE error IS NULL;

-- Virhesivut
SELECT url, status, error FROM pages WHERE error IS NOT NULL;

-- Linkkiverkosto
SELECT source_url, target_url FROM links;
```

**Python-esimerkki:**
```python
import sqlite3

conn = sqlite3.connect('data/crawler.db')
cursor = conn.cursor()

cursor.execute('SELECT url, title FROM pages WHERE status = 200')
for row in cursor.fetchall():
    print(row)
```

---

## ğŸ—ï¸ Arkkitehtuuri

```
src/
â”œâ”€â”€ config.py          # Konfiguraation lataus ja validointi
â”œâ”€â”€ tor_client.py      # Tor SOCKS5-yhteys + HTTP-pyynnÃ¶t
â”œâ”€â”€ parser.py          # HTML-parsinta ja linkkien eristÃ¤minen
â”œâ”€â”€ crawler.py         # BFS-algoritmi ja ydinlogiikka
â”œâ”€â”€ storage/
â”‚   â”œâ”€â”€ base.py        # Abstrakti tallennusluokka
â”‚   â”œâ”€â”€ json_storage.py   # NDJSON-tallennus
â”‚   â””â”€â”€ sqlite_storage.py # SQLite-tallennus
â””â”€â”€ utils.py           # Apufunktiot (URL-validointi, logger)
```

**Tietovirta:**
1. `main.py` lataa konfiguraation (`config.py`)
2. `TorCrawler` alustaa `TorClient`:n ja `Storage`:n
3. BFS-silmukka: Ota URL jonosta â†’ Hae `TorClient`:llÃ¤ â†’ Parsoi `HTMLParser`:llÃ¤ â†’ Tallenna `Storage`:en â†’ LisÃ¤Ã¤ linkit jonoon
4. Lopeta kun max_pages tai jono tyhjÃ¤

---

## ğŸ”’ Turvallisuus ja etiikka

### âš ï¸ TÃ„RKEÃ„Ã„

**SALLITTU kÃ¤yttÃ¶:**
- âœ… Tutkimus- ja oppimistarkoitukset
- âœ… Lailliset .onion-sivustot (julkiset hakemistot, tutkimuskohteet)
- âœ… Oma infrastruktuuri/testisivustot

**KIELLETTY kÃ¤yttÃ¶:**
- âŒ Laittomien .onion-sivustojen crawlaus
- âŒ Denial-of-Service (DoS) -hyÃ¶kkÃ¤ykset
- âŒ Palvelinten ylikuormittaminen
- âŒ Tunkeutumisyritykset
- âŒ HenkilÃ¶tietojen kaappaaminen
- âŒ KÃ¤yttÃ¤jien deanonymisointi

### Eettiset periaatteet

1. **Noudata lakeja:** Varmista ettÃ¤ toimintasi on laillista maassasi
2. **Kunnioita robots.txt:** Crawler kunnioittaa oletuksena robots.txt-tiedostoja
3. **Rate limiting:** Ã„LÃ„ poista tai pienennÃ¤ `request_delay`-arvoa (vÃ¤hintÃ¤Ã¤n 2-3 sekuntia)
4. **MaksimisivumÃ¤Ã¤rÃ¤:** Ã„lÃ¤ aseta `max_pages` liian korkeaksi (aloita <100)
5. **HenkilÃ¶tiedot:** Ã„lÃ¤ tallenna tai jaa henkilÃ¶kohtaisia tietoja
6. **Vastuu:** KÃ¤yttÃ¤jÃ¤ on vastuussa crawlerin kÃ¤ytÃ¶stÃ¤

### Tekniset turvallisuustoimet

- **Tor-yhteys:** Kaikki liikenne kulkee Tor-verkon kautta
- **Ei JavaScript:** Crawler ei suorita JavaScriptiÃ¤ (staattinen HTML)
- **SSL-validointi pois pÃ¤Ã¤ltÃ¤:** .onion-sivustoilla ei SSL-sertifikaatteja
- **Timeout:** Kaikki pyynnÃ¶t aikakatkaisevat (default 30s)
- **VirheenkÃ¤sittely:** Kattava try-except-logiikka

---

## ğŸ› VianmÃ¤Ã¤ritys

### Virhe: "Tor-yhteyttÃ¤ ei voitu muodostaa"

**Syy:** Tor ei ole kÃ¤ynnissÃ¤ tai portti on vÃ¤Ã¤rÃ¤.

**Ratkaisu:**
```bash
# Tarkista ettÃ¤ Tor on kÃ¤ynnissÃ¤
sudo systemctl status tor  # Linux
brew services list | grep tor  # macOS

# Testaa Tor-yhteyttÃ¤
curl --socks5-hostname 127.0.0.1:9050 https://check.torproject.org/api/ip

# Tarkista portti config.yaml:ssa (oletuksena 9050)
```

### Virhe: "Konfiguraatiotiedostoa ei lÃ¶ydy"

**Syy:** `config.yaml` puuttuu.

**Ratkaisu:**
```bash
cp config.example.yaml config.yaml
# Muokkaa config.yaml ja lisÃ¤Ã¤ start_url
```

### Timeout-virheitÃ¤ paljon

**Syy:** .onion-sivustot ovat hitaita tai offline.

**Ratkaisu:**
- Kasvata `request_timeout` arvoa (esim. 60)
- Kasvata `max_retries` arvoa (esim. 5)
- Tarkista ettÃ¤ sivusto on todella saavutettavissa Tor Browserilla

### ImportError: No module named 'stem'

**Syy:** Riippuvuuksia ei ole asennettu.

**Ratkaisu:**
```bash
pip install -r requirements.txt
```

---

## ğŸ“š Jatkokehitys

**Mahdolliset parannukset:**
- [ ] Robots.txt-tuki (parsinta ja kunnioittaminen)
- [ ] stem-integraatio (automaattinen IP-vaihto)
- [ ] JavaScript-renderÃ¶inti (Playwright/Selenium)
- [ ] Graafinen kÃ¤yttÃ¶liittymÃ¤ (web UI)
- [ ] Verkkoanalyysi (NetworkX, PageRank)
- [ ] Screenshot-tallennus
- [ ] Multi-threading/multiprocessing-tuki

---

## ğŸ“„ Lisenssi

TÃ¤mÃ¤ projekti on tarkoitettu **tutkimus- ja oppimistarkoituksiin**. KÃ¤yttÃ¤jÃ¤ on tÃ¤ysin vastuussa crawlerin kÃ¤ytÃ¶stÃ¤ ja siitÃ¤, ettÃ¤ toiminta on laillista.

**TekijÃ¤t eivÃ¤t ota vastuuta:**
- Laittomasta kÃ¤ytÃ¶stÃ¤
- Vahingosta kolmansille osapuolille
- Datan vÃ¤Ã¤rinkÃ¤ytÃ¶stÃ¤

---

## ğŸ™ Kiitokset

- **Tor Project** - Anonymiteetti ja yksityisyys
- **aiohttp** - Erinomainen asynkroninen HTTP-kirjasto
- **BeautifulSoup** - HTML-parsinta
- **Python-yhteisÃ¶** - Fantastinen ekosysteemi

---

## ğŸ“ Tuki

**Ongelmat?**
1. Lue [VianmÃ¤Ã¤ritys](#-vianmÃ¤Ã¤ritys)-osio
2. Tarkista Tor-yhteys
3. Tarkista konfiguraatio
4. KÃ¤ytÃ¤ `--log-level DEBUG` saadaksesi lisÃ¤tietoja

---

**HyvÃ¤Ã¤ tutkimusmatkaa! ğŸ”ğŸ§…**
